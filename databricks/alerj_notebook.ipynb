{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a38bbec6-4c83-4975-914d-76e1d89fefb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\n",
    "# spark.conf.set(\"spark.hadoop.fs.gs.auth.service.account.email\", \"bucket-bigquery@leafy-environs-409823.iam.gserviceaccount.com\")\n",
    "# spark.conf.set(\"spark.hadoop.fs.gs.project.id\", \"leafy-environs-409823\")\n",
    "# spark.conf.set(\"spark.hadoop.fs.gs.auth.service.account.private.key\", dbutils.secrets.get(scope='gcp-bucket', key='databricks-bucket-key'))\n",
    "# spark.conf.set(\"spark.hadoop.fs.gs.auth.service.account.private.key.id\", dbutils.secrets.get(scope='gcp-bucket', key='databricks-bucket-key_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130db065-d397-44db-8837-bec1e02d2c6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy\n",
    "%pip install python-Levenshtein\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1ff825c-bbf3-43d2-a98e-38239e141746",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col, when, regexp_replace, lit, levenshtein, rank, row_number, pandas_udf, length\n",
    "from pyspark.sql.types import FloatType, StringType, IntegerType\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.window import Window\n",
    "from re import sub\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eba571e-7979-43dd-bcc8-90f2382b0577",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GCP secret -> steps to install\n",
    "# databricks configure --token\n",
    "# databricks secrets create-scope gcp-bucket --initial-manage-principal users\n",
    "# databricks secrets put-secret gcp-bucket databricks-bucket-key\n",
    "# databricks secrets put-secret gcp-bucket databricks-bucket-key_id\n",
    "# Add config on Cluster Spark config https://docs.gcp.databricks.com/en/connect/storage/gcs.html\n",
    "\n",
    "print(dbutils.secrets.listScopes())\n",
    "print(dbutils.secrets.list('gcp-bucket'))\n",
    "\n",
    "dbutils.fs.ls(\"gs://bossa-bucket-coutj/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55e8bff2-63e5-45ad-a570-e3ba4958790a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#READING datasus raw data parquet\n",
    "\n",
    "dbutils.widgets.text(\"file_name\", \"\", \"Enter file_name\")\n",
    "file_name = dbutils.widgets.get('file_name') or '2016/folha_2016_1.parquet'\n",
    "# print(file_name)\n",
    "df = spark.read.parquet(f\"gs://bossa-bucket-coutj/raw/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83508e43-b779-4d26-91ab-7d8dccabffa8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove \"-\"\n",
    "\n",
    "for column in df.columns:\n",
    "    # print(column)\n",
    "    df = df.withColumn(column, when( col(column)=='-', None).otherwise(col(column)))\n",
    "    \n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18c6c055-f5ad-4e64-a10d-6f5a84f5bf3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fix currency format and cast string values to float\n",
    "numeric_columns = [col for col in df.columns if col not in ['nome', 'cargo', 'funcao']]\n",
    "\n",
    "for column in numeric_columns:\n",
    "    df = df.withColumn(\n",
    "                column, regexp_replace(col(column), \"\\.\", \"\")\n",
    "                ).withColumn(column, regexp_replace(column, \",\", \".\").cast(\"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434a477b-5ec4-411d-8ebf-754bcb0f696d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define data date\n",
    "\n",
    "date_str = re.search(r\"(?<=folha_)(.*)(?=\\.parquet)\",file_name).group(0).split('_')\n",
    "date = datetime.strptime(f\"{date_str[0]}/{date_str[1]}/1\",\"%Y/%m/%d\")\n",
    "table_name = f\"{date_str[0]}_{date_str[1]}\"\n",
    "# Add date column\n",
    "df = df.withColumn('date',lit(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4add3f19-a9c9-44f1-b0cd-b547b81a0494",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_table_schema = {\n",
    "    \"nome\": [\n",
    "        \"nome\"\n",
    "    ],\n",
    "    \"cargo\": [\n",
    "        \"cargo\"\n",
    "    ],\n",
    "    \"funcao\": [\n",
    "        \"funcao\"\n",
    "    ],\n",
    "    \"rendimento_do_funcionario\": [\n",
    "        \"rendfunc\",\n",
    "        \"rendfuncionario\",\n",
    "        \"rendimentos_do_funcionario\",\n",
    "        \"rendimento_func\",\n",
    "        \"rendimento_funcionario\",\n",
    "        \"vencimento\",\n",
    "        \"rendimento_do_funcionario\"\n",
    "    ],\n",
    "    \"comissao\": [\n",
    "        \"comissao\"\n",
    "    ],\n",
    "    \"representacao_grat_seguranca\": [\n",
    "        \"representacao_grat_seguranca\",\n",
    "        \"representacao_grat_segur\",\n",
    "        \"representacao_grat_segur_qualificacao\",\n",
    "        \"represent_grat_segur\",\n",
    "        \"representacao_grat_segur_grat_qualificacao_sfam\",\n",
    "        \"representacao_grat\",\n",
    "        \"representacao_qualificacao_grat_seguranca_s_fam\",\n",
    "        \"representacao_grat_seguranca_grat_qualificacao_s_fam\",\n",
    "        \"representacao_grat_segur_grat_qualificacao_s_fam\",\n",
    "        \"represent_gratseg\"\n",
    "    ],\n",
    "    \"incorporado\": [\n",
    "        \"incorporado\",\n",
    "        \"eignucrorporado\"\n",
    "    ],\n",
    "    \"trienio\": [\n",
    "        \"trienio\"\n",
    "    ],\n",
    "    \"bolsa_reforco_escolar\": [\n",
    "        \"abono_de_permanencia\",\n",
    "        \"bolsa_reforco_escolar_abono_permanencia\",\n",
    "        \"bolsa_reforco_escolar\"\n",
    "    ],\n",
    "    \"ferias\": [\n",
    "        \"ferias\"\n",
    "    ],\n",
    "    \"redutor\": [\n",
    "        \"redutor\"\n",
    "    ],\n",
    "    \"ipalerj_mensalidade\": [\n",
    "        \"ipalerj_mensalidade\",\n",
    "        \"ipalerj_mensalida_de\",\n",
    "        \"ipalerj_mens\"\n",
    "    ],\n",
    "    \"pensao_alimenticia\": [\n",
    "        \"pensao_alimenticia\"\n",
    "    ],\n",
    "    \"previdencia_inss\": [\n",
    "        \"previdencia_inss\",\n",
    "        \"previdencia\"\n",
    "    ],\n",
    "    \"imposto_de_renda\": [\n",
    "        \"ir\",\n",
    "        \"imposto_de_renda\",\n",
    "        \"imp_de_renda\"\n",
    "    ],\n",
    "    \"indenizatoria\": [\n",
    "        \"indenizatoria\"\n",
    "    ],\n",
    "    \"rendimento_liquido\": [\n",
    "        \"total_liquido\",\n",
    "        \"rendimento_liquido\"\n",
    "    ],\n",
    "    \"mes_referencia\": [\n",
    "        \"date\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Fix column names\n",
    "\n",
    "for column in df.columns:\n",
    "    col_orig_name = column\n",
    "    column = sub(\"(_{2,})\", \"_\", column)\n",
    "    found = False\n",
    "    for col_ref_name in out_table_schema:\n",
    "        if column in out_table_schema[col_ref_name]:\n",
    "            found = True\n",
    "            df = df.withColumnRenamed(col_orig_name, col_ref_name)\n",
    "            break\n",
    "        \n",
    "    if not found:\n",
    "        raise Exception(f\"Found columns not mapped on the schema: {column}\")\n",
    "\n",
    "# Adding empty non existing columns \n",
    "for schema_column in out_table_schema:\n",
    "    if schema_column not in df.columns:\n",
    "        df = df.withColumn(schema_column, lit(None))\n",
    "        df = df.withColumn(schema_column, col(schema_column).cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b93839e-9cf9-477a-a43d-3f54d1e5e09b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows with empty names\n",
    "\n",
    "df = df.na.drop(subset=['nome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72363616-9894-49f4-a6e0-9662413b810c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standardize role names (Teste fuzzywuzzy)\n",
    "\n",
    "\n",
    "positions = [\n",
    "    \"ASS. ESP. DE TECN. PARLAMENTAR\",\n",
    "    \"ASSESSOR\",\n",
    "    \"ASSESSOR ADJUNTO\",\n",
    "    \"ASSESSOR ASSISTENTE\",\n",
    "    \"ASSESSOR DA COORDENADORIA\",\n",
    "    \"ASSESSOR DE DIRETOR\",\n",
    "    \"ASSESSOR ESPECIAL\",\n",
    "    \"ASSESSOR ESPECIAL ADJUNTO\",\n",
    "    \"ASSESSOR ESPECIAL ASSISTENTE\",\n",
    "    \"ASSESSOR GABINETE\",\n",
    "    \"ASSESSOR PARLAMENTAR I\",\n",
    "    \"ASSESSOR PARLAMENTAR II\",\n",
    "    \"ASSESSOR PARLAMENTAR III\",\n",
    "    \"ASSESSOR PARLAMENTAR IV\",\n",
    "    \"ASSESSOR PARLAMENTAR IX\",\n",
    "    \"ASSESSOR PARLAMENTAR V\",\n",
    "    \"ASSESSOR PARLAMENTAR VI\",\n",
    "    \"ASSESSOR PARLAMENTAR VII\",\n",
    "    \"ASSESSOR PARLAMENTAR VIII\",\n",
    "    \"ASSESSOR TEC. PARLAMENTAR\",\n",
    "    \"ASSIST. DE DIRETOR DE DIVISAO\",\n",
    "    \"ASSISTENTE ADJUNTO\",\n",
    "    \"ASSISTENTE DE COORDENADORIA\",\n",
    "    \"ASSISTENTE DE DIRETOR DE DEPTO\",\n",
    "    \"ASSISTENTE I\",\n",
    "    \"ASSISTENTE II\",\n",
    "    \"ASSISTENTE III\",\n",
    "    \"ASSISTENTE IV\",\n",
    "    \"ASSISTENTE IX\",\n",
    "    \"ASSISTENTE PRESIDENTE COMISSAO\",\n",
    "    \"ASSISTENTE SUB-DIRETOR GERAL\",\n",
    "    \"ASSISTENTE V\",\n",
    "    \"ASSISTENTE VI\",\n",
    "    \"ASSISTENTE VII\",\n",
    "    \"ASSISTENTE VIII\",\n",
    "    \"AUXILIAR ADMINISTRATIVO\",\n",
    "    \"AUXILIAR DE GABINETE\",\n",
    "    \"AUXILIAR ESPECIAL\",\n",
    "    \"AUXILIAR I\",\n",
    "    \"AUXILIAR II\",\n",
    "    \"AUXILIAR III\",\n",
    "    \"AUXILIAR IV\",\n",
    "    \"AUXILIAR LEGISLATIVO\",\n",
    "    \"AUXILIAR V\",\n",
    "    \"CHEFE DE GABINETE DIRETOR GERAL\",\n",
    "    \"CHEFE DE GABINETE\",\n",
    "    \"CHEFE DE GABINETE PARLAMENTAR\",\n",
    "    \"CHEFE DE GABINETE PRES.\",\n",
    "    \"CHEFE GABINETE LIDERANCA\",\n",
    "    \"CHEFE GABINETE SUPL. LIDER.\",\n",
    "    \"CHEFE GABINETE PRIMEIRO SECRETARIO\",\n",
    "    \"CHEFE GABINETE SECRETARIAS\",\n",
    "    \"CHEFE GABINETE VICE PRES.\",\n",
    "    \"CHEFE GABINETE VOGAL\",\n",
    "    \"CONSULTOR ESP. P/ ASSUNT. PARLA.\",\n",
    "    \"CONTROLADOR\",\n",
    "    \"COORD P/ ASSUNTOS MILITARES\",\n",
    "    \"COORD. DE ALMOXARIFADO\",\n",
    "    \"COORD. DE BENS PATRIMONIAS\",\n",
    "    \"COORD. DE COMUNICACOES\",\n",
    "    \"COORD. DE ODONTOLOGIA\",\n",
    "    \"COORD. DE PORTARIA\",\n",
    "    \"COORDENADOR DE DIVISAO\",\n",
    "    \"COORDENADOR DE ENFERMAGEM\",\n",
    "    \"COORDENADOR DE OFICINA\",\n",
    "    \"DIRETOR DE DEPARTAMENTO\",\n",
    "    \"DIRETOR GERAL ALERJ\",\n",
    "    \"ENCARREGADO DE SETOR\",\n",
    "    \"MEMBRO DE COMISSAO\",\n",
    "    \"PRESIDENTE COMIS. LICITACAO\",\n",
    "    \"PRESIDENTE DA C.P.P.A\",\n",
    "    \"PRESIDENTE DE COMISSAO\",\n",
    "    \"PROCURADOR GERAL\",\n",
    "    \"REDATOR DE ASSUNTOS CONSTITUICAO\",\n",
    "    \"SECRETARIO DE COMISSAO\",\n",
    "    \"SECRETARIO GERAL\",\n",
    "    \"SECRETARIO GERAL MS DIRETORA\",\n",
    "    \"SUBCHEFE DE GABINETE\",\n",
    "    \"SUBDIRETOR GERAL ADMINISTRACAO\",\n",
    "    \"SUBDIRETOR GERAL ALERJ\",\n",
    "    \"SUBDIRETOR GERAL ASSUNTOS LEGISLATIVOS\",\n",
    "    \"SUBDIRETOR GERAL CERIMONIAL\",\n",
    "    \"SUBDIRETOR GERAL COM SOCIAL\",\n",
    "    \"SUBDIRETOR GERAL DE CONTROLE INTERNO\",\n",
    "    \"SUBDIRETOR GERAL ENG ARQUIT\",\n",
    "    \"SUBDIRETOR GERAL ESCOLA DO LEGISLATIVO\",\n",
    "    \"SUBDIRETOR GERAL FINANCAS\",\n",
    "    \"SUBDIRETOR GERAL FORUM PERM\",\n",
    "    \"SUBDIRETOR GERAL INFORMATICA\",\n",
    "    \"SUBDIRETOR GERAL RECURSOS HUMANOS\",\n",
    "    \"SUBDIRETOR GERAL SEGURANCA\",\n",
    "    \"SUBDIRETOR GERAL TV ALERJ\",\n",
    "    \"SUBPROCURADOR GERAL\",\n",
    "    \"SUBPROCURADOR GERAL ADJUNTO\",\n",
    "    \"SUPERINTENDENTE II\",\n",
    "    \"SUPERINTENDENTE IV\",\n",
    "    \"VOGAL\"\n",
    "]\n",
    "\n",
    "df_positions = spark.createDataFrame([ [pos] for pos in positions], StructType([StructField('funcoes', StringType(), True)]))\n",
    "\n",
    "df_funcoes_orig = df.select(col('funcao').alias(\"funcao_orig\")).distinct()\n",
    "\n",
    "# display(df_funcoes_orig)\n",
    "\n",
    "df_cross_join_funcao = df_funcoes_orig.crossJoin(df_positions)\n",
    "\n",
    "@udf(IntegerType())\n",
    "def matchstring(s1, s2):\n",
    "    return fuzz.token_sort_ratio(s1, s2)\n",
    "\n",
    "df_cross_join_funcao = df_cross_join_funcao.withColumn('distancia', matchstring(col('funcao_orig'), col('funcoes')))\n",
    "\n",
    "df_cross_join_funcao = (\n",
    "    df_cross_join_funcao\n",
    "    .filter(col('funcao_orig').isNotNull())\n",
    "    .withColumn('rank', row_number().over(Window.partitionBy('funcao_orig').orderBy(col(\"distancia\").desc())))\n",
    "    .groupBy('funcao_orig', 'funcoes', 'distancia').min('rank').filter(col('min(rank)') == 1)\n",
    "    )\n",
    "\n",
    "df_cross_join_funcao = df_cross_join_funcao.withColumn('result', when(col('distancia') > 80, col('funcoes')).otherwise(col('funcao_orig')))\n",
    "df_cross_join_funcao = df_cross_join_funcao[['funcao_orig', 'result']]\n",
    "\n",
    "df = df.join(df_cross_join_funcao, df.funcao == df_cross_join_funcao.funcao_orig, how='left')\n",
    "df = df.withColumn('funcao', col('result'))\n",
    "df = df.drop(*['funcao_orig', 'result'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f52af1f6-40c1-435c-afa3-23745747f15f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standardize cargo\n",
    "\n",
    "df = (df.withColumn('cargo', when(length('cargo') <= 3, None)\n",
    "        .when(col('cargo').rlike(\"^[^A-Za-z].*$\"), None)\n",
    "        .otherwise(col('cargo')))\n",
    "    )\n",
    "\n",
    "positions = [\n",
    "    \"ASSESSOR PARLAMENTAR I\",\n",
    "    \"ASSESSOR PARLAMENTAR II\",\n",
    "    \"ASSESSOR PARLAMENTAR III\",\n",
    "    \"ASSESSOR PARLAMENTAR IV\",\n",
    "    \"ASSESSOR PARLAMENTAR V\",\n",
    "    \"ASSESSOR PARLAMENTAR VI\",\n",
    "    \"ASSESSOR PARLAMENTAR VII\",\n",
    "    \"ASSESSOR PARLAMENTAR VIII\",\n",
    "    \"ASSESSOR PARLAMENTAR IX\",\n",
    "    \"ASSISTENTE I\",\n",
    "    \"ASSISTENTE II\",\n",
    "    \"ASSISTENTE III\",\n",
    "    \"ASSISTENTE IV\",\n",
    "    \"ASSISTENTE V\",\n",
    "    \"ASSISTENTE VI\",\n",
    "    \"ASSISTENTE VII\",\n",
    "    \"ASSISTENTE VIII\",\n",
    "    \"ASSISTENTE IX\",\n",
    "    \"ASSISTENTE X\",\n",
    "    \"AUXILIAR I\",\n",
    "    \"AUXILIAR II\",\n",
    "    \"AUXILIAR III\",\n",
    "    \"AUXILIAR IV\",\n",
    "    \"AUXILIAR V\",\n",
    "    \"AUXILIAR VI\",\n",
    "    \"AUXILIAR VII\",\n",
    "    \"AUXILIAR VIII\",\n",
    "    \"AUXILIAR IX\",\n",
    "    \"AUXILIAR X\",\n",
    "    \"AUXILIAR ADMINISTRATIVO\",\n",
    "    \"AUXILIAR ESPECIAL\",\n",
    "    \"AUXILIAR LEGISLATIVO\",\n",
    "    \"CONSULTOR TECNICO\",\n",
    "    \"DEPUTADO ESTADUAL\",\n",
    "    \"ENCARREGADO DE SETOR\",\n",
    "    \"ESPEC LEG NIV – 1\",\n",
    "    \"ESPEC LEG NIV – 2\",\n",
    "    \"ESPEC LEG NIV – 3\",\n",
    "    \"ESPEC LEG NIV – 4\",\n",
    "    \"ESPEC LEG NIV – 5\",\n",
    "    \"ESPEC LEG NIV – 6\",\n",
    "    \"ESPEC LEG NIV – 7\",\n",
    "    \"ESPEC LEG NIV – 8\",\n",
    "    \"ESPEC LEG NIV – 9\",\n",
    "    \"ESPEC LEG NIV – 10\"\n",
    "]\n",
    "\n",
    "df_positions = spark.createDataFrame([ [pos] for pos in positions], StructType([StructField('cargos', StringType(), True)]))\n",
    "\n",
    "df_cargos_orig = df.select(col('cargo').alias(\"cargo_orig\")).distinct()\n",
    "\n",
    "df_cross_join_cargo = df_cargos_orig.crossJoin(df_positions)\n",
    "\n",
    "@udf(IntegerType())\n",
    "def matchstring(s1, s2):\n",
    "    return fuzz.token_set_ratio(s1, s2)\n",
    "\n",
    "df_cross_join_cargo = df_cross_join_cargo.withColumn('distancia', matchstring(col('cargo_orig'), col('cargos')))\n",
    "\n",
    "df_cross_join_cargo = (\n",
    "    df_cross_join_cargo\n",
    "    .filter(col('cargo_orig').isNotNull())\n",
    "    .withColumn('rank', row_number().over(Window.partitionBy('cargo_orig').orderBy(col(\"distancia\").desc())))\n",
    "    .groupBy('cargo_orig', 'cargos', 'distancia').min('rank').filter(col('min(rank)') == 1)\n",
    "    )\n",
    "\n",
    "df_cross_join_cargo = df_cross_join_cargo.withColumn('result', when(col('distancia') > 80, col('cargos')).otherwise(col('cargo_orig')))\n",
    "df_cross_join_cargo = df_cross_join_cargo[['cargo_orig', 'result']]\n",
    "\n",
    "df = df.join(df_cross_join_cargo, df.cargo == df_cross_join_cargo.cargo_orig, how='left')\n",
    "df = df.withColumn('cargo', col('result'))\n",
    "df = df.drop(*['cargo_orig', 'result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a0becf4-df7e-46dc-9f51-0180eee03187",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    bq_lines = (spark.read.format('bigquery')\n",
    "        .option('table', f\"leafy-environs-409823.alerj_ds.alerj_payslip\")\n",
    "        .option(\"parentProject\", 'leafy-environs-409823')\n",
    "        .load())\n",
    "    bq_lines.createOrReplaceTempView('bq_table_view')\n",
    "\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT * FROM bq_table_view where \n",
    "            nome=\"{df.first()[\"nome\"]}\" AND\n",
    "            mes_referencia=\"{df.first()[\"mes_referencia\"]}\" AND\n",
    "            rendimento_liquido=\"{df.first()[\"rendimento_liquido\"]}\"\n",
    "        \"\"\"\n",
    "    existing_data = spark.sql(sql_query)\n",
    "except Exception as e:\n",
    "    if \"alerj_ds.alerj_payslip\" in str(e.java_exception):\n",
    "        empty_schema = StructType([])\n",
    "        existing_data = spark.createDataFrame([], schema=empty_schema)\n",
    "    else:\n",
    "        raise Exception(f\"Error Reading From BigQuery: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cdd04ea-b5b2-4492-b7e2-96c55797033b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write dataframe to Bigquery:\n",
    "if not len(existing_data.take(1)):\n",
    "    (df.write.format(\"bigquery\")\n",
    "        .mode(\"append\")\n",
    "        .option(\"project\", 'leafy-environs-409823')\n",
    "        .option(\"parentProject\", 'leafy-environs-409823')\n",
    "        .option(\"temporaryGcsBucket\",\"bossa-bucket-coutj\")\n",
    "        .option(\"table\",f\"leafy-environs-409823.alerj_ds.alerj_payslip\")\n",
    "        .save())\n",
    "    \n",
    "    df.write.mode('overwrite').parquet(f'gs://bossa-bucket-coutj/trusted/{file_name}')\n",
    "else:\n",
    "    print(\"Data Already Exists\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "alerj_notebook",
   "widgets": {
    "file_name": {
     "currentValue": "2016/folha_2016_8.parquet",
     "nuid": "29a7b234-cc1c-4f35-9bb4-09160fff663d",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter file_name",
      "name": "file_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
